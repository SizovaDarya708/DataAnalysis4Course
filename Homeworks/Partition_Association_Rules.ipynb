{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Apriori as ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание данных(взят из открытых источников)\n",
    "\n",
    "Данные содержат в себе список продуктов бакалейного, продуктового магазина в одном чеке.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('GroceryStoreDataSet.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MILK,BREAD,BISCUIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BREAD,MILK,BISCUIT,CORNFLAKES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREAD,TEA,BOURNVITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JAM,MAGGI,BREAD,MILK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAGGI,TEA,BISCUIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0\n",
       "0             MILK,BREAD,BISCUIT\n",
       "1  BREAD,MILK,BISCUIT,CORNFLAKES\n",
       "2            BREAD,TEA,BOURNVITA\n",
       "3           JAM,MAGGI,BREAD,MILK\n",
       "4              MAGGI,TEA,BISCUIT"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 0\n",
      "0               MILK,BREAD,BISCUIT\n",
      "1    BREAD,MILK,BISCUIT,CORNFLAKES\n",
      "2              BREAD,TEA,BOURNVITA\n",
      "3             JAM,MAGGI,BREAD,MILK\n",
      "4                MAGGI,TEA,BISCUIT\n",
      "5              BREAD,TEA,BOURNVITA\n",
      "6             MAGGI,TEA,CORNFLAKES\n",
      "7          MAGGI,BREAD,TEA,BISCUIT\n",
      "8              JAM,MAGGI,BREAD,TEA\n",
      "9                       BREAD,MILK\n",
      "10  COFFEE,COCK,BISCUIT,CORNFLAKES\n",
      "11  COFFEE,COCK,BISCUIT,CORNFLAKES\n",
      "12          COFFEE,SUGER,BOURNVITA\n",
      "13               BREAD,COFFEE,COCK\n",
      "14             BREAD,SUGER,BISCUIT\n",
      "15         COFFEE,SUGER,CORNFLAKES\n",
      "16           BREAD,SUGER,BOURNVITA\n",
      "17              BREAD,COFFEE,SUGER\n",
      "18              BREAD,COFFEE,SUGER\n",
      "19      TEA,MILK,COFFEE,CORNFLAKES\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support=0.25\n",
    "partition1 = data[0:int(len(data)/2)]\n",
    "partition2 = data[int(len(data)/2):len(data)]\n",
    "partition1.to_csv('part1.csv',index=False,header=None)\n",
    "partition2.to_csv('part2.csv',index=False,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARTITION алгоритм (A. Savasere, E. Omiecinski and S. Navathe, 1995 год).**\n",
    "Этот алгоритм разбиения (разделения) заключается в сканировании транзакционной базы данных путем разделения ее на непересекающиеся разделы, каждый из которых может уместиться в оперативной памяти, в данном случае разделение на две csv таблицы(part1, part2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_set1 = ap.Apriory('part1.csv',min_support)\n",
    "freq_set1 = [list(x) for x in freq_set1]\n",
    "freq_set2 = ap.Apriory('part2.csv',min_support)\n",
    "freq_set2 = [list(x) for x in freq_set2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_set = freq_set1\n",
    "for i in range(len(freq_set2)):\n",
    "    if(freq_set2[i] not in freq_set):\n",
    "        freq_set.append(freq_set2[i])\n",
    "#freq_set = [set(x) for x in freq_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На первом шаге в каждом из разделов при помощи алгоритма Apriori определяются \"локальные\" часто встречающиеся наборы данных. На втором подсчитывается поддержка каждого такого набора относительно всей базы данных. Таким образом, на втором этапе определяется множество всех потенциально встречающихся наборов данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               0\n",
      "0             MILK,BREAD,BISCUIT\n",
      "1  BREAD,MILK,BISCUIT,CORNFLAKES\n",
      "2            BREAD,TEA,BOURNVITA\n",
      "3           JAM,MAGGI,BREAD,MILK\n",
      "4              MAGGI,TEA,BISCUIT\n",
      "5            BREAD,TEA,BOURNVITA\n",
      "6           MAGGI,TEA,CORNFLAKES\n",
      "7        MAGGI,BREAD,TEA,BISCUIT\n",
      "8            JAM,MAGGI,BREAD,TEA\n",
      "9                     BREAD,MILK\n"
     ]
    }
   ],
   "source": [
    "dataPart1 = pd.read_csv('part1.csv',header=None)\n",
    "print(dataPart1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                0\n",
      "0  COFFEE,COCK,BISCUIT,CORNFLAKES\n",
      "1  COFFEE,COCK,BISCUIT,CORNFLAKES\n",
      "2          COFFEE,SUGER,BOURNVITA\n",
      "3               BREAD,COFFEE,COCK\n",
      "4             BREAD,SUGER,BISCUIT\n",
      "5         COFFEE,SUGER,CORNFLAKES\n",
      "6           BREAD,SUGER,BOURNVITA\n",
      "7              BREAD,COFFEE,SUGER\n",
      "8              BREAD,COFFEE,SUGER\n",
      "9      TEA,MILK,COFFEE,CORNFLAKES\n"
     ]
    }
   ],
   "source": [
    "dataPart2 = pd.read_csv('part2.csv', header=None)\n",
    "print(dataPart2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MILK,BREAD,BISCUIT\n",
      "Добавлен:\n",
      "['MILK', 'BREAD', 'BISCUIT']\n",
      "...\n",
      "BREAD,MILK,BISCUIT,CORNFLAKES\n",
      "Добавлен:\n",
      "['BREAD', 'MILK', 'BISCUIT', 'CORNFLAKES']\n",
      "...\n",
      "BREAD,TEA,BOURNVITA\n",
      "Добавлен:\n",
      "['BREAD', 'TEA', 'BOURNVITA']\n",
      "...\n",
      "JAM,MAGGI,BREAD,MILK\n",
      "Добавлен:\n",
      "['JAM', 'MAGGI', 'BREAD', 'MILK']\n",
      "...\n",
      "MAGGI,TEA,BISCUIT\n",
      "Добавлен:\n",
      "['MAGGI', 'TEA', 'BISCUIT']\n",
      "...\n",
      "BREAD,TEA,BOURNVITA\n",
      "Добавлен:\n",
      "['BREAD', 'TEA', 'BOURNVITA']\n",
      "...\n",
      "MAGGI,TEA,CORNFLAKES\n",
      "Добавлен:\n",
      "['MAGGI', 'TEA', 'CORNFLAKES']\n",
      "...\n",
      "MAGGI,BREAD,TEA,BISCUIT\n",
      "Добавлен:\n",
      "['MAGGI', 'BREAD', 'TEA', 'BISCUIT']\n",
      "...\n",
      "JAM,MAGGI,BREAD,TEA\n",
      "Добавлен:\n",
      "['JAM', 'MAGGI', 'BREAD', 'TEA']\n",
      "...\n",
      "BREAD,MILK\n",
      "Добавлен:\n",
      "['BREAD', 'MILK']\n",
      "...\n",
      "COFFEE,COCK,BISCUIT,CORNFLAKES\n",
      "Добавлен:\n",
      "['COFFEE', 'COCK', 'BISCUIT', 'CORNFLAKES']\n",
      "...\n",
      "COFFEE,COCK,BISCUIT,CORNFLAKES\n",
      "Добавлен:\n",
      "['COFFEE', 'COCK', 'BISCUIT', 'CORNFLAKES']\n",
      "...\n",
      "COFFEE,SUGER,BOURNVITA\n",
      "Добавлен:\n",
      "['COFFEE', 'SUGER', 'BOURNVITA']\n",
      "...\n",
      "BREAD,COFFEE,COCK\n",
      "Добавлен:\n",
      "['BREAD', 'COFFEE', 'COCK']\n",
      "...\n",
      "BREAD,SUGER,BISCUIT\n",
      "Добавлен:\n",
      "['BREAD', 'SUGER', 'BISCUIT']\n",
      "...\n",
      "COFFEE,SUGER,CORNFLAKES\n",
      "Добавлен:\n",
      "['COFFEE', 'SUGER', 'CORNFLAKES']\n",
      "...\n",
      "BREAD,SUGER,BOURNVITA\n",
      "Добавлен:\n",
      "['BREAD', 'SUGER', 'BOURNVITA']\n",
      "...\n",
      "BREAD,COFFEE,SUGER\n",
      "Добавлен:\n",
      "['BREAD', 'COFFEE', 'SUGER']\n",
      "...\n",
      "BREAD,COFFEE,SUGER\n",
      "Добавлен:\n",
      "['BREAD', 'COFFEE', 'SUGER']\n",
      "...\n",
      "TEA,MILK,COFFEE,CORNFLAKES\n",
      "Добавлен:\n",
      "['TEA', 'MILK', 'COFFEE', 'CORNFLAKES']\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "newdata = []\n",
    "for i in range(len(data)):\n",
    "    temp = data[0][i]\n",
    "    print(data[0][i])\n",
    "    newdata.append(temp.split(','))\n",
    "    print('Добавлен:')\n",
    "    print(temp.split(','))\n",
    "    print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 13, 7, 7, 5, 4, 4, 4, 3, 4, 8, 3, 6, 6, 3, 4, 4, 3, 4]\n",
      "20\n",
      "Frequent Set is :  [['MILK'], ['BREAD'], ['BISCUIT'], ['TEA'], ['MAGGI'], ['COFFEE'], ['CORNFLAKES'], ['SUGER']]\n"
     ]
    }
   ],
   "source": [
    "count = [0 for i in range(len(freq_set))]\n",
    "for i in range(len(newdata)):\n",
    "    for j in range(len(freq_set)):\n",
    "        if(set(freq_set[j]).issubset(set(newdata[i]))):\n",
    "            count[j] = count[j]+1\n",
    "            \n",
    "final_freq_set = []\n",
    "for i in range(len(freq_set)):\n",
    "    if (count[i]>=min_support*len(data)):\n",
    "        final_freq_set.append(freq_set[i])\n",
    "print('Frequent Set is : ',final_freq_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
